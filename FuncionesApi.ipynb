{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo las librerias que se voy a utilizar.\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo el archivo CSV en un DataFrame para poder utilizarlo.\n",
    "df = pd.read_csv('plataformas.csv',parse_dates=['date_added'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Crear 7 funciones para la FastApi:<b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Película (sólo película, no serie, ni documentales, etc) con mayor duración según año, plataforma y tipo de duración. La función debe llamarse get_max_duration(year, platform, duration_type) y debe devolver sólo el string del nombre de la película.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_duration(anio: int, plataforma: str, dtype: str):\n",
    "    \n",
    "    # Me aseguro que si el usuario escribe en mayusculas se pase a minusculas.\n",
    "    dtype = dtype.lower()\n",
    "    platform = plataforma.lower()[0] #Aclaro indice en 0 para que tome la primer letra\n",
    "\n",
    "    # Filtro por año de lanzamiento, plataforma aclarando que solo tenga en cuenta la primer letra de la columna id y que el tipo sea 'movie'.\n",
    "    data_filtrada = df[(df['release_year'] == anio) & (df['id'].str.startswith(platform)) & (df['duration_type'] == dtype) & (df['type'] == 'movie')]\n",
    "    \n",
    "    # Busco la duración máxima dentro del conjunto de datos filtrados\n",
    "    max_duration = data_filtrada['duration_int'].max()\n",
    "    # Busco la fila que contiene la duración máxima dentro del conjunto de datos filtrados\n",
    "    max_duration_row = data_filtrada.loc[data_filtrada['duration_int'] == max_duration]    \n",
    "     \n",
    "    #me aseguro que no este vacia para ser entregada.   \n",
    "    if not max_duration_row.empty:\n",
    "        # Si se encontró una fila con la duración máxima, se obtiene el nombre de la\n",
    "        # película correspondiente (es decir, la película con la duración máxima)\n",
    "        # extrayendo el valor de la columna 'title' de la fila.\n",
    "        movie_name = max_duration_row['title'].iloc[0]\n",
    "        \n",
    "        return {'pelicula': movie_name}\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return {'No se encontraron peliculas que cumplan con los criterios de busqueda.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pelicula': 'unbreakable kimmy schmidt: kimmy vs. the reverend'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_duration(2020,'NETFLIX','min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pelicula': 'soothing surf at del norte for sleep black screen'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_duration(2018,'amazon','min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pelicula': \"dory's reef cam\"}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_duration(2020,'disney','min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pelicula': 'crock of gold: a few rounds with shane macgowan'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_duration(2020,'hulu','min')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cantidad de películas (sólo películas, no series, ni documentales, etc) según plataforma, con un puntaje mayor a XX en determinado año. La función debe llamarse get_score_count(platform, scored, year) y debe devolver un int, con el total de películas que cumplen lo solicitado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_count(plataforma: str, scored: float, year: int):\n",
    "      \n",
    "    # Me aseguro que si el usuario escribe en mayus se pase a minusculas, en el caso de plataform solo me interesa la primer letra.\n",
    "    platform = plataforma.lower()[0]#Aclaro indice en 0 para que tome la primer letra\n",
    "        \n",
    "    # Filtro por año de lanzamiento, plataforma aclarando que solo tenga en cuenta la primer letra de la columna id y que el tipo sea 'movie'.   \n",
    "    data_filtrada = df[(df['id'].str.startswith(platform)) & (df['release_year'] == year) & (df['type'] == 'movie')]\n",
    "    \n",
    "    # Cuento la cantidad de películas que tienen el rating deseado\n",
    "    count = data_filtrada[data_filtrada['score'] > scored]['id'].count()\n",
    "    \n",
    "    return {'plataforma': plataforma,\n",
    "            'cantidad': int(count),\n",
    "            'anio': year,\n",
    "            'score': scored}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'NetFlix', 'cantidad': 190, 'anio': 2020, 'score': 3.5}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score_count('NetFlix',3.5, 2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'amazon', 'cantidad': 267, 'anio': 2020, 'score': 3.5}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score_count('amazon',3.5, 2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'hulu', 'cantidad': 83, 'anio': 2020, 'score': 3.5}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score_count('hulu',3.5, 2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'disney', 'cantidad': 34, 'anio': 2020, 'score': 3.5}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score_count('disney',3.5, 2020)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cantidad de películas (sólo películas, no series, ni documentales, etc) según plataforma. La función debe llamarse get_count_platform(platform) y debe devolver un int, con el número total de películas de esa plataforma. Las plataformas deben llamarse amazon, netflix, hulu, disney.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_platform(plataforma: str):\n",
    "        \n",
    "    # Me aseguro que si el usuario escribe en mayus se pase a minusculas, en el caso de plataforma solo me interesa la primer letra.\n",
    "    platform = plataforma.lower()[0]#Aclaro indice en 0 para que tome la primer letra\n",
    "    \n",
    "    # Realizo el filtro para que cuente del dataframe solo la plataforma de la columna id y movie de la columna type.\n",
    "    data_filtrada = df[(df['id'].str.startswith(platform)) & (df['type'] == 'movie')].shape[0]# Realizo el .shape en 0 para que me traiga solo la cantidad de filas que hay de ese filtro.    \n",
    "\n",
    "    return {'plataforma': plataforma,\n",
    "            'peliculas': data_filtrada}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'hulu', 'peliculas': 1484}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_count_platform('hulu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'amazon', 'peliculas': 7814}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_count_platform('amazon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'disney', 'peliculas': 1052}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_count_platform('disney')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'netflix', 'peliculas': 6131}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_count_platform('netflix')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Actor que más se repite según plataforma y año. La función debe llamarse get_actor(platform, year) y debe devolver sólo el string con el nombre del actor que más se repite según la plataforma y el año dado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(plataforma: str, anio: int):    \n",
    "    \n",
    "    # Me aseguro que si el usuario escribe en mayus se pase a minusculas, en el caso de plataform solo me interesa la primer letra.\n",
    "    platform = plataforma.lower()[0]#Aclaro indice en 0 para que tome la primer letra\n",
    "    \n",
    "    # Realizo el filtro para que cuente del dataframe solo la plataforma de la columna id y el añio.\n",
    "    data_filtrada = df[(df['id'].str.startswith(platform)) & (df['release_year'] == anio)]   \n",
    " \n",
    "    # En este paso, se utiliza la función dropna() de pandas para eliminar los valores NaN de la columna \"cast\" del DataFrame. \n",
    "    # Luego utilizo el método apply() para aplicar la función str() a cada valor de la columna \"cast\", convirtiendo los valores a cadenas de caracteres. \n",
    "    # Finalmente, se utiliza el método str.split(',') para dividir cada cadena de caracteres en una lista de actores utilizando la coma como separador\n",
    "    # y un .strip para que extraiga cualquier valor que sea tipo digito(No enteros si no un .digit). \n",
    "    # El resultado es una serie de pandas que contiene una lista de actores para cada fila del DataFrame original, ignorando cualquier registro extraño.\n",
    "    actores_por_fila = data_filtrada['cast'].dropna().apply(lambda x: [i.strip() for i in x.split(',') if not i.strip().isdigit()])\n",
    "    \n",
    "    # Cuento la cantidad de veces que aparece cada actor en todas las filas, utilizando la clase Counter de Python.\n",
    "    contador_actores = Counter()\n",
    "    for actores in actores_por_fila:\n",
    "        # Actualizamos el contador de actores con un nuevo conjunto de actores.\n",
    "        # Si el contador ya tenía un registro para un actor específico, se incrementa su\n",
    "        # valor en 1. De lo contrario, se crea un nuevo registro para ese actor con un\n",
    "        # valor inicial de 1.\n",
    "        contador_actores.update(actores)\n",
    "\n",
    "    # Encuentro el actor que aparece más veces utilizando la funcion most common devolviendo una lista de tuplas donde cada tupla contiene un actor \n",
    "    # y la cantidad de veces que aparece en todas las filas del DataFrame.\n",
    "    actor_mas_repetido = contador_actores.most_common(1)# El 1 indica que se muestre 1 solo valor.\n",
    "    \n",
    "    #se verifica si la lista actor_mas_repetido no está vacía.\n",
    "    if actor_mas_repetido:\n",
    "        # se asigna a actor_mas_repetido el primer elemento de la primera tupla en la lista actor_mas_repetido, que contiene el actor que aparece más veces.\n",
    "        actor_mas_repetido = actor_mas_repetido[0][0]\n",
    "    else:\n",
    "        return {'plataforma': plataforma,\n",
    "                'anio': anio,\n",
    "                'actor': \"No hay datos disponibles\",\n",
    "                'apariciones': \"No hay datos disponibles\"}\n",
    "\n",
    "    # Muestro el actor que aparece más veces y la cantidad de veces que aparece\n",
    "    cantidad_actor_mas_repetido = contador_actores[actor_mas_repetido]\n",
    "    return {'plataforma': plataforma,\n",
    "            'anio': anio,\n",
    "            'actor': actor_mas_repetido,\n",
    "            'apariciones': cantidad_actor_mas_repetido}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'amazon', 'anio': 2021, 'actor': 'om nom', 'apariciones': 10}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_actor('amazon',2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'hulu',\n",
       " 'anio': 2020,\n",
       " 'actor': 'No hay datos disponibles',\n",
       " 'apariciones': 'No hay datos disponibles'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_actor('hulu',2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'netflix',\n",
       " 'anio': 2020,\n",
       " 'actor': 'blossom chukwujekwu',\n",
       " 'apariciones': 6}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_actor('netflix',2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plataforma': 'disney',\n",
       " 'anio': 2020,\n",
       " 'actor': 'daveed diggs',\n",
       " 'apariciones': 3}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_actor('disney',2020)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La cantidad de contenidos/productos (todo lo disponible en streaming) que se publicó por país y año. La función debe llamarse prod_per_county(tipo,pais,anio) deberia devolver el tipo de contenido (pelicula,serie) por pais y año en un diccionario con las variables llamadas 'pais' (nombre del pais), 'anio' (año), 'pelicula' (tipo de contenido).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_per_county(tipo: str, pais: str, anio: int):   \n",
    "    \n",
    "    # Realizo un filtro para que busque por tipo, año de lanzamiento y que el campo \"country\" contenga el país.\n",
    "    data_filtrada = df[(df['type'] == tipo) & (df['release_year'] == anio) & (df['country'].str.contains(pais))]\n",
    "    # Creo un diccionario vacío para contar la cantidad de películas por país\n",
    "    count_por_pais = {}\n",
    "\n",
    "    # Recorro cada fila del DataFrame y cada lista de países en ella\n",
    "    for countries in data_filtrada['country']:\n",
    "        \n",
    "        # Separo los países de la lista y los recorro\n",
    "        for country in countries.split(','):\n",
    "            \n",
    "            # Elimino los espacios en blanco al inicio y al final del país\n",
    "            country = country.strip()\n",
    "            \n",
    "            # Verifico si el país ya existe en el diccionario, si no es así lo agrego y le asigno un valor de 0\n",
    "            if country not in count_por_pais:\n",
    "                count_por_pais[country] = 0\n",
    "                \n",
    "            # Incremento en 1 la cantidad de películas para ese país en el diccionario\n",
    "            count_por_pais[country] += 1 \n",
    "               \n",
    "    # Obtener el recuento de películas para el país especificado\n",
    "    respuesta = count_por_pais.get(pais, 0)\n",
    "    \n",
    "    return {'pais': pais,\n",
    "            'anio': anio,            \n",
    "            'peliculas': respuesta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pais': 'united arab emirates', 'anio': 2014, 'peliculas': 5}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_per_county('movie','united arab emirates' , 2014)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La cantidad total de contenidos/productos (todo lo disponible en streaming, series, documentales, peliculas, etc) según el rating de audiencia dado (para que publico fue clasificada la pelicula). La función debe llamarse get_contents(rating) y debe devolver el numero total de contenido con ese rating de audiencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contents(rating: str):       \n",
    "    \n",
    "    #Realizo un .value_counts de rating en base al rating que pongan.    \n",
    "    respuesta =  df['rating'].value_counts()[rating]\n",
    "\n",
    "    return {'rating': rating,\n",
    "            'contenido': int(respuesta)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rating': 'g', 'contenido': 1269}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_contents('g')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistema de recomendación:\n",
    "\n",
    "Una vez que toda la data es consumible por la API, está lista para consumir por los departamentos de Analytics y Machine Learning, y nuestro EDA nos permite entender bien los datos a los que tenemos acceso, es hora de entrenar nuestro modelo de machine learning para armar un sistema de recomendación de películas. Éste consiste en recomendar películas a los usuarios basándose en películas similares, por lo que se debe encontrar la similitud de puntuación entre esa película y el resto de películas, se ordenarán según el score y devolverá una lista de Python con 5 valores, cada uno siendo el string del nombre de las películas con mayor puntaje, en orden descendente. Debe ser deployado como una función adicional de la API anterior y debe llamarse get_recommendation(titulo: str)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Version A<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una instancia de TfidfVectorizer con stop words en inglés\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Convierto los títulos en una matriz TF-IDF\n",
    "tfidf_matrix = tfidf.fit_transform(df['title'])\n",
    "\n",
    "\n",
    "def get_recommendations(title: str):\n",
    "    #Me aseguro que si escriben en mayuscula llevarlo a minuscula.\n",
    "    title = title.lower()\n",
    "    # Creo una serie con los índices de las películas y sus títulos correspondientes\n",
    "    indices = pd.Series(df.index, index=df['title'])\n",
    "    # Obtengo el índice de la película que se quiere buscar\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Calculo la similitud coseno entre la película buscada y todas las demás\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[idx], tfidf_matrix)\n",
    "    # Obtengo las similitudes y sus índices correspondientes\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    # Ordeno las similitudes de mayor a menor\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Tomo las 5 películas más similares (excluyendo la misma película buscada)\n",
    "    sim_scores = sim_scores[1:6]\n",
    "    # Obtengo los índices de las películas más similares\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    # Obtengo los títulos de las películas más similares y los retornamos como una lista\n",
    "    respuesta = df['title'].iloc[movie_indices].tolist()\n",
    "    return {'recomendacion': respuesta}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recomendacion': ['the grand',\n",
       "  'five grand',\n",
       "  'grand hotel',\n",
       "  'the grand tour',\n",
       "  'grand army']}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('the grand seduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recomendacion': ['tarzan',\n",
       "  'tarzan',\n",
       "  'tarzan 2',\n",
       "  'tarzan ii',\n",
       "  'come on, tarzan']}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('tarzan')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Version B<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendationsB(title: str):\n",
    "           \n",
    "    #Me aseguro que si escriben en mayuscula llevarlo a minuscula.\n",
    "    title = title.lower()    \n",
    "    \n",
    "    # Creo una instancia de TfidfVectorizer.\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # Aplico el vectorizador a la columna 'listed_in' para obtener la matriz de características\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['listed_in'])\n",
    "    \n",
    "    # Calculo la matriz de similitud de coseno\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # Obtengo el índice de la película que coincide con el título proporcionado\n",
    "    idx = df.index[df['title'] == title.lower()].tolist()[0]\n",
    "\n",
    "    # Obtengo las puntuaciones de similitud de coseno de la película con todas las demás películas\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Ordeno las películas según las puntuaciones de similitud\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Obtengo las cinco películas más similares, excluyendo la película de entrada\n",
    "    sim_scores = [i for i in sim_scores if df.index[i[0]] != idx]\n",
    "    sim_scores = sim_scores[:5]\n",
    "\n",
    "    # Obtengo los títulos de las cinco películas más similares\n",
    "    recomendaciones = df.iloc[[i[0] for i in sim_scores]]['title'].tolist()\n",
    "\n",
    "    return {'recomendacion': recomendaciones}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recomendacion': [\"summer '03\",\n",
       "  'z: the beginning of everything',\n",
       "  'you, me and him',\n",
       "  'walter',\n",
       "  'waiting on mary']}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendationsB('the grand seduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recomendacion': ['on happiness road',\n",
       "  'invincible',\n",
       "  'metal skin panic madox-1',\n",
       "  'series before 1c onboarding - 2',\n",
       "  'nuttiest nutcracker']}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendationsB('tarzan')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERSION C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendationsC(title: str):\n",
    "    \n",
    "    #Me aseguro que si escriben en mayuscula llevarlo a minuscula.\n",
    "    title = title.lower()\n",
    "    \n",
    "    #Leo el ccsv que utilizo.\n",
    "    df_corr = pd.read_csv('ML.csv')\n",
    "    \n",
    "    # Creo el vectorizador TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # Aplico el vectorizador a la columna 'listed_in' para obtener la matriz de características\n",
    "    tfidf_matrix = vectorizer.fit_transform(df_corr['title'])\n",
    "    \n",
    "    # Calculo la matriz de similitud de coseno\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix) \n",
    "    idx = df_corr.index[df_corr['title'] == title.lower()].tolist()[0]\n",
    "    \n",
    "    # Obtengo las puntuaciones de similitud de coseno de la película con todas las demás películas\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    \n",
    "    # Ordeno las películas según las puntuaciones de similitud\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Obtengo las cinco películas más similares, excluyendo la película de entrada\n",
    "    sim_scores = [i for i in sim_scores if df_corr.index[i[0]] != idx]\n",
    "    sim_scores = sim_scores[:5]\n",
    "    \n",
    "    # Obtengo los títulos de las cinco películas más similares\n",
    "    recomendaciones = df_corr.iloc[[i[0] for i in sim_scores]]['title'].tolist()\n",
    "\n",
    "    return {'recomendacion': recomendaciones}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recomendacion': ['the grand',\n",
       "  'five grand',\n",
       "  'grand isle',\n",
       "  'winged seduction: birds of paradise',\n",
       "  'into the grand canyon']}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendationsC('the grand seduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recomendacion': ['tarzan',\n",
       "  'tarzan',\n",
       "  'tarzan 2',\n",
       "  'tarzan ii',\n",
       "  'tarzan & jane']}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendationsC('tarzan')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERSION D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.read_csv('ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendationsD(title: str):  \n",
    "    #Me aseguro que si escriben en mayuscula llevarlo a minuscula.\n",
    "    title = title.lower()\n",
    "      \n",
    "    # Creo el vectorizador TF-IDF\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # Aplico el vectorizador a la columna para obtener la matriz de características.\n",
    "    tfidf_matrix = tfidf.fit_transform(df_corr['categorias'])\n",
    "    \n",
    "    # Obtengo el índice de la película que coincide con el título proporcionado\n",
    "    idx = df_corr.index[df_corr['title'] == title.lower()].tolist()[0]\n",
    "    \n",
    "    # Calculo la matriz de similitud de coseno\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[idx], tfidf_matrix)\n",
    "    \n",
    "    # Obtengo las puntuaciones de similitud de coseno de la película con todas las demás películas\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    \n",
    "    # Ordeno las películas según las puntuaciones de similitud\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Obtengo las cinco películas más similares, excluyendo la película de entrada\n",
    "    sim_scores = [i for i in sim_scores if i[0] != idx]\n",
    "    sim_scores = sim_scores[:5]\n",
    "    \n",
    "    # Obtengo los títulos de las cinco películas más similares\n",
    "    recomendaciones = df_corr.iloc[[i[0] for i in sim_scores]]['title'].tolist()\n",
    "    \n",
    " \n",
    "    return {'recomendacion': recomendaciones} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recomendacion': ['take care good night',\n",
       "  'grease live!',\n",
       "  \"david's mother\",\n",
       "  'take care',\n",
       "  \"summer '03\"]}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendationsD('the grand seduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recomendacion': ['stay tuned',\n",
       "  'technotise: edit & i',\n",
       "  'on happiness road',\n",
       "  'the congress',\n",
       "  'shrek 2']}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendationsD('tarzan')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERSION FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recomendation(title: str):    \n",
    "    \n",
    "    #Me aseguro que si escriben en mayuscula llevarlo a minuscula.\n",
    "    title = title.lower()\n",
    "    \n",
    "    # Creo el vectorizador TF-IDF\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # Aplico el vectorizador a la columna para obtener la matriz de características.\n",
    "    tfidf_matrix = tfidf.fit_transform(df_corr['categorias'])\n",
    "    \n",
    "    # Obtengo el índice de la película que coincide con el título proporcionado\n",
    "    idx = df_corr.index[df_corr['title'] == title.lower()].tolist()[0]\n",
    "    \n",
    "    # Calculo la matriz de similitud de coseno\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[idx], tfidf_matrix)\n",
    "    \n",
    "    # Obtengo las puntuaciones de similitud de coseno de la película con todas las demás películas\n",
    "    sim_scores = list(enumerate(cosine_sim[0]))\n",
    "    \n",
    "    # Ordeno las películas según las puntuaciones de similitud\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Obtengo las películas similares con la mejor puntuación de score\n",
    "    sim_scores = [i for i in sim_scores if i[0] != idx]\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: df_corr['score'].iloc[x[0]], reverse=True)[:5]\n",
    "    \n",
    "    # Obtengo los títulos de las películas seleccionadas\n",
    "    respuesta = df_corr.iloc[[i[0] for i in sim_scores]]['title'].tolist()\n",
    "    \n",
    "    \n",
    "    return {'recomendacion': respuesta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recomendacion': ['take care good night',\n",
       "  'grease live!',\n",
       "  \"david's mother\",\n",
       "  'take care',\n",
       "  \"summer '03\"]}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recomendation('the grand seduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recomendacion': ['stay tuned',\n",
       "  'technotise: edit & i',\n",
       "  'on happiness road',\n",
       "  'the congress',\n",
       "  'shrek 2']}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recomendation('tarzan')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
